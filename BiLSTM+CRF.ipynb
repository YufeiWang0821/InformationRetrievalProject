{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import dataset2dataloader\n",
    "from models import BiLSTM_CRF_NER\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, sent_vocab, tag_vocab = dataset2dataloader(batch_size=128)\n",
    "word_vectors = sent_vocab.vectors\n",
    "\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里由于BiLSTM的数据处理问题，出现了如下报错  \n",
    "`RuntimeError: 'lengths' argument should be a 1D CPU int64 tensor, but got 1D cuda:0 Long tensor`  \n",
    "这似乎是由于在进行文本嵌入的时候，调用的`nn.Embedding`函数的问题  \n",
    "由于**时间**关系我暂时只能先使`device = torch.device('cpu')`  \n",
    "按照老师所说，后面的NLP专选课实验也会使用BiLSTM+CRF实现NER，届时可能会解决这一问题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF_NER(vocab_size=len(sent_vocab.stoi), embedding_dim=50, hidden_size=128, num_tags=len(tag_vocab.stoi), word_vectors=word_vectors, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "learning_rate = 0.01\n",
    "model_path = \"model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, iter:0, loss:5228.29833984375 epoch:0, iter:100, loss:342.710205078125 epoch 10 train acc:0.97, val acc:0.94\n",
      "epoch:1, iter:0, loss:211.81451416015625 epoch:1, iter:100, loss:70.90070343017578 epoch 10 train acc:0.99, val acc:0.96\n",
      "epoch:2, iter:0, loss:72.41127014160156 epoch:2, iter:100, loss:44.5744743347168 epoch 10 train acc:1.00, val acc:0.96\n",
      "epoch:3, iter:0, loss:19.108728408813477 epoch:3, iter:100, loss:35.543296813964844 epoch 10 train acc:1.00, val acc:0.97\n",
      "epoch:4, iter:0, loss:16.934940338134766 epoch:4, iter:100, loss:11.126664161682129 epoch 10 train acc:1.00, val acc:0.96\n",
      "epoch:5, iter:0, loss:4.5881476402282715 epoch:5, iter:100, loss:5.764562606811523 epoch 10 train acc:1.00, val acc:0.96\n",
      "epoch:6, iter:0, loss:1.6615972518920898 epoch:6, iter:100, loss:1.5588173866271973 epoch 10 train acc:1.00, val acc:0.95\n",
      "epoch:7, iter:0, loss:1.6595497131347656 epoch:7, iter:100, loss:0.116668701171875 epoch 10 train acc:1.00, val acc:0.96\n",
      "epoch:8, iter:0, loss:0.49768829345703125 epoch:8, iter:100, loss:0.48386573791503906 epoch 10 train acc:1.00, val acc:0.96\n",
      "epoch:9, iter:0, loss:0.3464536666870117 epoch:9, iter:100, loss:0.2817878723144531 epoch 10 train acc:1.00, val acc:0.96\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(model_path):\n",
    "    model = torch.load(model_path)\n",
    "else:\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            x, y = batch.sent.t(), batch.tag.t()\n",
    "            mask = (x != sent_vocab.stoi[\"<pad>\"])\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(x, y, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                print(f\"epoch:{ep}, iter:{i}, loss:{loss.item()}\", end=\" \")\n",
    "\n",
    "        model.eval()\n",
    "        train_accs = []\n",
    "        preds, golds = [], []\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            x, y = batch.sent.t(), batch.tag.t()\n",
    "            mask = (x != sent_vocab.stoi[\"<pad>\"])\n",
    "            with torch.no_grad():\n",
    "                preds = model.predict(x, mask)\n",
    "            right, total = 0, 0\n",
    "            for pred, gold in zip(preds, y):\n",
    "                right += np.sum(np.array(pred) == gold[:len(pred)].numpy())\n",
    "                total += len(pred)\n",
    "            train_accs.append(right*1.0/total)\n",
    "        train_acc = np.array(train_accs).mean()\n",
    "\n",
    "        val_accs = []\n",
    "        for i, batch in enumerate(val_iter):\n",
    "            x, y = batch.sent.t(), batch.tag.t()\n",
    "            mask = (x != sent_vocab.stoi[\"<pad>\"])\n",
    "            with torch.no_grad():\n",
    "                preds = model.predict(x, mask)\n",
    "            right, total = 0, 0\n",
    "            for pred, gold in zip(preds, y):\n",
    "                right += np.sum(np.array(pred) == gold[:len(pred)].numpy())\n",
    "                total += len(pred)\n",
    "            val_accs.append(right * 1.0 / total)\n",
    "        val_acc = np.array(val_accs).mean()\n",
    "        print(\"epoch %d train acc:%.2f, val acc:%.2f\" % (epoch, train_acc, val_acc))\n",
    "torch.save(model, model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_sents = [\"My name is Yufei Wang , I am from Jinzhou , Hubei , China .\"]\n",
    "#test_sents = [\"HUST is the abbreviation of Huazhong University of Science and Technology . It is located in Hongshan , Wuhan , China .\"]\n",
    "test_sents = [\"Sufjan Stevens released his thirteenth album Carrie and Lowell on March 31 , 2015 in America and received a high score of 9 . 3 from Pitchfork .\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里修改文本以获得输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in test_sents:\n",
    "    ids = [sent_vocab.stoi[word] for word in sent.split(\" \")]\n",
    "    input_tensor = torch.tensor([ids])\n",
    "    mask = input_tensor != sent_vocab.stoi[\"<pad>\"]\n",
    "    with torch.no_grad():\n",
    "        pred = model.predict(input_tensor, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sufjan Stevens released his thirteenth album Carrie and Lowell on March 31 , 2015 in America and received a high score of 9 . 3 from Pitchfork . \n",
      " ['B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-PER', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-ORG', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sent, \"\\n\", [tag_vocab.itos[tag_id] for tag_id in pred[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简要地测试了几条文本，可以看出大部分`PER`、`LOC`和`ORG`都可以成功识别，但是对于日期等`MISC`识别效果较差"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
